
print('The answer is \u0664\u662 today')

[Instructor] In this lesson we're going to do all the preparation necessary to make a publisher/subscriber service. You've already laid a really solid foundation up to this point and now we just want to cover some extra pieces that we're going to need. We'll talk about Unicode normalization, practice making name tuples, also we'll have to use the reverse and key arguments, the sorted, bisect and one that you might not have used before, which is merge. We'll use itertools islice to chop off data from data streams. We'll use sys.intern to conserve memory space. A reminder from the first lesson, random expovariate, which is normally used to model arrival times but can also be used to create variable length response times, and time delays in a web service. We'll show time sleep and time time. In hashlib, I'll show off a couple of popular patches, sha 256, sha 512. And a wonderful tool that has an unpronounceable name, PBKDF2 HMAC, which represents the state-of-the-art in hashing technology and is a best practice. We'll show how to get the repr of a tuple, how to join strings together floor division, the ternary operator, and a unique feature of Python, that is And and Or short-circuiting boolean operators will return a value whether there's a boolean. And with that preparation in place, we'll be able to rapidly make a publisher subscriber service, we'll be able to express really big ideas with only a little amount of code. All right, let's go ahead and lay the groundwork. First of all, let's talk about Unicode. Unicode will allow us to print out regular ASCII characters, but also some more interesting characters like "the answer is backslash u0664, backslash u0662 today". Those are Arabic-ending digits to print the number of 42. One thing I don't like is having these magic constants in our code, and in order to balance that out, what we can do is use the names for the Unicode characters, for instance, how do I like to teach, it's the Raymond way. So unique that perhaps, I ought to trademark it. But see, that looks very 1980s. How do we fix it? A little bit of Unicode will help, I can collapse it in and use a backslash N to use a named Unicode code point, perhaps a trademark sign, which is a clearer way of making exactly the same string. One of the challenges of Unicode is sometimes there's more than one way to make the same string. There's a Core developer whose name is Martin von Löwis and one way to spell his name is by using code point 246. Martin von Löwis built your Windows distributions, is a famous Python and Core developer and has contributed an enormous amount to the language. But he has more than one way of inputting his name. He could also use 776 combined with code point 111. Let's see how these two strings look. We'll print s, Martin von Löwis, and print t. Those two strings look exactly the same. However, if we list out all of their components, the ord of a character, for every character in s, and the ord of the character for every character in t, you'll see that t is a little bit longer and that s is a little bit shorter, and even though they visually look the same, they're actually distinct strings and are not equal to each other. So if Martin von Löwis was one of your users in a system and he typed in his name in one example and then typed in his name using another technique for another example, you might end up not finding his name in the system. And it would be mysterious to you because the two look like they're the same, like they should be there. So there's a technique for correcting this and it's in Unicode data module, and it's called normalization. U is equal to Unicode data, normalize, and there's a couple styles of normalization, the one that shrinks is NFC, and apply that to t. With that transformation in place, U is now the same as the original s. And so, typically, when you're getting in Unicode data that you're going to have to look up later, you should always normalize it first, that way the lookups will match. Next up is name tuples. Name tuples are very easy to create. They are in the collections module. We've already used them several times, and the idea is, instead of a tuple where the fields aren't self-explanatory, we would like to be able to look the fields up by name. So name tuple is a factory function that creates new classes. The name of this class is person, and its field names are first name, last name, age and email address. I can go ahead and create a person object, perhaps myself, person, f name Raymond, Hettinger. Being a subclass of tuple, you can expect that a name tuple will have tuple-like properties. It has a len, it's unpackable, just like regular tuples. It's sliceable just like regular tuples, and it's indexable like regular tuples. The differences are that it has a better repr, the representation clearly identifies what all of the fields are, and you can also access the fields by name. This goes a long way towards making your code self-documenting and making it beautiful. All of the named accesses are much clearer than the equivalent index accesses. My recommendation is to go through all your code, and wherever you're passing around tuples that aren't self-explanatory or where the index lookups aren't making perfect sense, add in a name tuple. Next topic is working with sorted data and with bisect. Bisect is a particularly interesting module, and a lot of people don't realize exactly what it is for. They think that bisect is about searching for a particular item. But we have a better searching tool, the better searching tool is hashtables implemented in the form of dictionaries. So, if you have to look something up, you just look it up in a dictionary. It's very fast, faster than bisect, which raises the question, what is bisect for? Bisect is all about searching inside ranges. When we look inside ranges, we're looking at the gaps in between all of the cut points. If you take a piece of rope and you cut it one time, you get two pieces. If you cut it two times, you get three pieces. The number of cuts is always one greater, or the number of sections of ropes is always one greater than the number of cuts. So an example would be, here are some cut points. A score of 60 on a test, a 70 on a test, an 80 on a test or a 90 on a test. If you cut the piece of rope four times, you get five pieces, so the pieces that correspond to these cuts are a grade of F, D, C, B and A. Notice how we have one more grade than cut points. What bisect does is efficiently search the cut points. So bisect bisect, we go to look through the cut points and look up a particular grade for, you make a 76 on the test and you'd like to know what grade is associated with that 76. This can be done in a list comprehension so that you can grade some papers. You've got a score, for score in, some sample grades. We have a 76, a 92, an 80, a 70, a 69 and 99 and a 100. Let's see, what I've just done wrong here, we have the bisect for score in these grades, I've just closed the score. Just closed the bisect, ah, we can see the problem here. We need to close the indexed lookup. Make the screen a little bit wider and you can see the grades on these papers range from C to A. I picked these numbers for a reason so that we could see that 80 was at a cut point and bisect, by default, switches to the right-most grade after the 80, so at 80 and 81 we'll get exactly the same scores. If needed, bisect has a bisect left option which will push to the left side of the cut. So what do you use bisect for? Bisect is mainly used for searching ranges. You want to search tax tables, for example, bisect is perfect for that. In the US income tax brackets, let's go take a look at some of these tax brackets. It's a table showing ranges of incomes and if your income falls between these two values, your tax rate is 25%, our marginal tax rate, for example. What we could do is make a dictionary that listed every value between 37,650 and 91,150 and do lookups that way. But if you just want to store the cut points or break points, bisect is perfect for searching this. We say bisect is all about searching ranges and not searching for particular values. Now let's look at sorting. Sorting takes a sequence that is non-sorted and, of course, ranges it in sorted order. So, in this case, we have our one list that's being ranged in ascending order. What'd be interesting is, what if we had several lists to put together? Perhaps another one that is a list of 1, 11 and 25. Well, the first step we're doing is concatenating, which makes a brand new list, and then sorted goes through and attempts to put these in sorted order. Which is a perfectly reasonable operation if I need to take two separate unsorted lists, combine them together and then sort the aggregate. That said, suppose the lists are already sorted. I had a series of lists that had 1, 11 and 25, which is already sorted, and I had a second list, 5, 10 and 20, and a third list, 2, 15 and 21. And I would like to combine them together and sort them. One way to do it is to aggregate the list and then run sort on them, but as these lists get larger and larger, this is somewhat inefficient, because we're not taking advantage of the fact that we already know that the sub-lists are in sorted order. Effectively, what we'd like to do is an operation called a merge. And we've got a tool to do that in the heapq module. From heapq, import, merge. If I were to list the merge of a, b and c, that would combine them all together. This is far more efficient than sorting. One of the interesting things is merge works left to right, it creates an iterator, and the iterator doesn't actually do the merging until we ask for a value. So, the moment I ask for next, it looks for the lowest value out of the three lists. It advances the pointer on the first list up to the 11, and the only three things it has in memory is the 2, the 5 and the 11. Out of those, the 2 is smallest. It then advances the pointer on the next list to the 15. Why would this matter? Well, suppose these lists were very, very, very long, but known to be sorted, and suppose you only wanted the first few elements of the combined lists. What we could do is use merge and then next off just the first elements that we needed. So, if you imagine these lists are long, this is a very efficient way to pull out the lowest elements in the combination. We'll be needing that in the publisher/subscriber service. Now, pulling these off one at a time with next is reasonable if all we're doing is getting one or two at a time. But if we want more of them, we can use the in the itertools module, islice. Islice is a wonderful tool. It works just like regular slicing, although it only goes in a forward direction, and it works over iterators. Let me demonstrate this with a regular iterable. Islice, with only one argument, will give us a stop point. A, B, C, D, E, F, G, H, I, I want the first three elements. I can also tell it another way that says start at the beginning, go to the end. So none is the default for the start point. But I could also tell it, give me between two and four. Further, it can do a start, stop and step. Start at the beginning, go up to four and count by twos. This is just like the regular slice notation. The part that's different, though, is it can consume an iterator and produce an iterator, meaning it doesn't have to eat all of the values on the way in. This'll be very useful with our list. So, when we'd made a merge, that created an iterator. A generator is a kind of iterator that runs code on demand. Now I would like the first three elements of the merge. What I'd like to do is islice the merge, and say, capture the first three. What's nice about this is all three lists don't have to be combined and resorted. Instead, it works left to right over the lists and if the lists are very long, it will pull out just the elements we need. This'll be really important for us when we're making web services or when you're running data queries. Consider when you run a query on a search engine, and it tells you there's 200 thousand matches for your query. Do you want all 200 thousand displayed? No, and it would be inefficient for the search engine to actually produce all 200 thousand when you're only going to look at the first 10. So a reasonable thing to do is to get an iterator over the search query, run an islice over it, display the first 10 results. And the user selects the next page, say I want the next 10 results. So it's quite common, when you have data arranged to where the most relevant information comes first and least relevant comes later. Either arranged by time, newest things first, oldest things first, you can use islice to capture that data stream and capture just the pieces that you need. So islice will work together with merge to do a just in time sort as we need information over potentially very large data sources. The next one up is going to be interning of strings. For the most part, because strings are immutable, it doesn't matter whether a string is mentioned multiple times in memory or only once. From a user's point of view, two different strings in memory that have the same contents are treated exactly the same, which raises the question, if they're exactly the same and they're immutable, why have more than one? What interning does is it folds two cases together into a single case, and it's mainly used to save memory. I'll build an he and separate, an llo. And combine them together and make a hello. We'll compare that to s plus t. U and v look exactly the same. U and v are equal to each other. But the identities of the objects are, in fact, two different strings. So we can enter the notion of string interning, and it's in the sys module. And the idea is when we go to make u, we can go interning. This says, save an example of it and be able to look it up later and make sure it is the only example of this string. Then, when we build v, we can intern that one as well. That will look to see if we already have an existing hello, and if so, it will reuse that one. Now, not only are u and v equal to each other, u and v are the same object in memory. This doesn't matter so much for a string like a hello, but if you have usernames, for example, you don't want the same username appearing many different times in memory. In fact, whenever you're building table-style information, perhaps a list of name tuples, the recurring values in there, you can save memory by interning each of the values.
